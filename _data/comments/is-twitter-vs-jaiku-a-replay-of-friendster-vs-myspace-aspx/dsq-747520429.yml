id: dsq-747520429
date: 2007-05-20T15:29:34.0000000-07:00
name: Sam Smoot
avatar: https://disqus.com/api/users/avatars/Sam Smoot.jpg
message: <p>I wouldn't count on Twitter fixing it's scaling problems very quickly.<br>I mean, they could obviously. If Rails is the cause (and let's face it, what else could it be?), then it's not like the problems are so large that they'd take very long to work out.<br>Sticking your head in the sand and trying to work around core design issues isn't going to get you anywhere in the long run though. Side-skirting fundamental design flaws is band-aiding at best. It doesn't look like most Rails developers (or Twitter for that matter) have got to that place where they're willing to accept that some cows are holy for a reason though.<br>Here's a rather straight-forward solution to Rails performance woes:<br>  * Less "beauty" in the framework itself (not necessarily in your application), smaller call-stacks.<br>  * Embrace the language. Don't invent your own variable-bags when instance variables would do.<br>  * Fowler and the GoF are better architects than most anyone else. Ignore their advice on how to implement "X" at your own peril.<br>I've been lazy the past few months, but with these guide-lines I was able to create my DataMapper project and easily able to boost performance vs ActiveRecord anywhere from 2x to 10x. That's just 1 part of Rails. And you don't give up anything (well, aside from maturity, lots of eyes, support for lots of databases, etc). The syntax for usage is actually even more terse, even more magical.<br>The Merb project does much the same for the ActionPack side of things, boosting the performance of a simple "HelloWorld" application to almost 700 requests-per-second.<br>I think I've read Twitters real, average load is actually around 600 requests-per-second.<br>So say Rails+ActiveRecord nets you around 10 optimized, uncached requests-per-second. This is a loaded "write" action. Where the performance bottlenecks really start hurtin' you.<br>Say Merb+DataMapper nets youd around 50.<br>How much administrative/hardware/concurrency/locking overhead can you avoid if you suddenly start getting 5X the throughput from the same processes? Not to mention the much nicer user experience from an average latency of 20ms vs 100ms.<br>...but the community isn't quite there yet I think. We'll go on about pompous-sounding typography issues while completely ignoring usability studies that say there are few more black &amp; white issues on the web than latency when it comes to visitor retention. But we'll get there eventually. :-) And for some of us, with very cache-friendly applications, it really doesn't matter that much if it takes awhile for that day to roll around.</p>
