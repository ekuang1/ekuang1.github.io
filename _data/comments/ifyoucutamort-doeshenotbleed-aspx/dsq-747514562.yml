id: dsq-747514562
date: 2006-03-25T17:29:00.0000000-08:00
name: Ian Griffiths
avatar: https://disqus.com/api/users/avatars/Ian Griffiths.jpg
message: <p>The sequential shift doesn't reduce the leak in the abstraction. Quite the opposite - it's an admission that automatic transmission is the wrong abstraction, dropping you back at the lower level abstraction. In this case that's an improvement as manual gear selection is better than automatic, despite what Joel Spolsky thinks. I'm guessing he's a bad driver. :)<br>(Why's it better? More control, better fuel economy, and most importantly, none of the aggravating constant drain on your attention required in order to anticipate what the gearbox is going to do next and work around it in the rather high proportion of scenarios where it does the wrong thing. The only situation in which an automatic gearbox is less mentally draining is when your engine is heavily overprovisioned for the kind of driving you're doing, in which case it barely matters what gear you're in, so long as you're within 2 or 3 gears of the theoretical optimum. And actually for run of the mill driving that's a reasonably common scenario, particularly if you're unfortunate enough to live somewhere without interesting roads. But personally, I like to *enjoy* my driving - I try to avoid mind-numbing drives. And for any remotely engaging driving, automatic transmission is a special kind of hell.)<br>The only problem I have with Mort is not that he wants higher levels of abstraction, but that in my experience he tends not to want to think about the abstraction at all.<br>Abstractions are a code thing, and code isn't where Mort's interests lie. Higher levels of abstraction are only interesting to him to the extent that they enable him not to engage his brain with the code. (The popular presumption being that his brain is engaged with business logic instead. As a developer it's sometimes hard to believe that the brain was engaged at all judging from the code...) High level abstractions increase the probability that random hacking will lead reasonably quickly to a result that approximates what Mort thinks he wants well enough that he'll call it a day.<br>After all, Mort's in it for the results. The code is just a means to an end.<br>But this leads to exactly the kind of problem you describe.<br>There's nothing wrong with high-level abstractions if they are clean, and well-thought-out. The simplest possible solution is often beautiful to behold. But it typically belies how much thought went into its creation - the simplest looking solutions tend to require the most effort to achieve.<br>But Mort doesn't care for that - he's not interested in the quality of the abstraction per se. He's only interested in how little he can do before stopping coding.<br>This only affects me when either (a) I have to fix some monstrosity created by a Mort, or (b) a beautifully designed library is broken in order to reduce the initial cognitive overhead required to use it at the expense of simplicity of use from within mature code.<br>(And is there a way of turning off live preview on your comments? This is like typing in mollasses!)</p>
