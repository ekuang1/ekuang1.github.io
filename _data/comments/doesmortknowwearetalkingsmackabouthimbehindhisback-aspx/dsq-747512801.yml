id: dsq-747512801
date: 2008-04-28T14:22:09.0000000-07:00
name: millenomi
avatar: https://disqus.com/api/users/avatars/millenomi.jpg
message: "<p>@AndyB; I think you miss the point.<br>Most of the framework changes that are made are <em>advances</em> over previous situations. We strive because no matter how much the tools seem well-suited, we -- in the sense of the programmers and scientists in the field -- always find areas to improve or challenges to overcome.<br>Thus, I feel that it is not unreasonable to demand of a programmer that he or she keep in touch with these advances. They're usually done for a reason, not for some Sadic Scientist's whim.<br>About \"<em> *We* need to step up to the plate and realise that writing software is about producing business applications that solve business needs, not anything to do with 'technology'</em>\", I cannot really understand how you can take technology out of information technology. I agree that systems should not be built out of some new technology just because it appeals to the programmers, but this is no excuse for keeping track of changes and trying to understand why they're occurring. If we didn't, we'd still be programming in COBOL.<br>Re: GC, .NET's garbage collector <em>does</em> make it much easier to avoid inadvertently leaking memory. In VB6, if you have a cycle of objects, they'll never leave memory, due to the reference counting that's done under the scenes -- and you'll be none the wiser. With .NET, this is no longer true, because cycles are collected. <em>This does not mean that it's impossible to leak memory, only that it's much harder to do so from programmer code</em>. (Your rebuttal also reveals your ignorance of the gist of the problem: it's probably the underlying .NET virtual machine that leaked memory, not the Princeton code, -- I don't think Princeton PhDs are Morts, nor the virtual machine designers, but the VM was likely written in C and we know how much of a hell low-level manual memory management is.)<br></p>"
