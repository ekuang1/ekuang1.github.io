id: dsq-747509291
date: 2004-08-15T22:09:00.0000000-07:00
name: Ian Griffiths
avatar: https://disqus.com/api/users/avatars/Ian Griffiths.jpg
message: <p>"However, if I were expecting a huge number of simultaneous connections, I might look into changing the machine.config file to support more than 25 ThreadPool threads per processor"<br><br><br><br>Actually, even in these cases the threadpool is very often still the way to go.<br><br><br><br>Suppose you have a glut of requests all arriving in very quick succession from 100 clients. (They won't arrive simultaneously of course, unless you have managed to get 100 network adapters in your machine...  But if the requests are small, and your network card is fast, then might arrive faster than you can process them, in which case they're as near to arriving at once as makes no difference.)<br><br><br><br>Given such a wodge of requests, which do you suppose will be the faster of these two approaches:<br><br><br><br>(1) Have a small number of threads processing the requests, and let the majority of the requests sit in the thread pool's queue until you're ready to process them.<br><br><br><br>(2) Attempt to handle all of them simultaneous on 100 threads.<br><br><br><br>Of course it depends on how much work you need to do to handle the request, but you said you only need to do a very short amount of processing. My guess is that for this scenario (1) will work better in that particular case. And in general, Windows doesn't really like having hundreds of runnable threads - it usually performs better if you have a small number. Indeed, server products like SQL Server and ASP.NET go out of their way to try and make sure that the number of runnable threads (i.e. threads with CPU work to do right now, and which aren't blocked waiting for something to happen) to be equal to the number of CPUs whenever possible.<br><br><br><br>If the work being done consists mostly of waiting for other stuff to happen, then it may be different. So if you have to send a request to a DB and wait for the response, then you'll spend most of your time blocking. In this case, bumping up the thread count can help things. (Although if you go too far, you may simply end up asking too much of the DB...)<br><br><br><br>But for anything where most of the work is CPU-bound, you tend to want to minimize the number of threads.<br><br><br><br>So the fact that the thread pool queues up work until there's a CPU available to do that work often improves performance.<br><br><br><br>Of course your advice - "measure measure measure" is the most important thing. I'm just pointing out that in my experience, increasing the number of concurrent threads more often makes things worse, not better. Indeed, I've known of some web sites that *reduced* the thread pool maximum from 25 down to 7 or 8, and found that their system throughput increased as a result. Mainly because the system simply wasn't able to process 25 requests simultaneously, and got better throughput by trying to process just 7 or 8 simultaneously.</p>
